{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Telegram Chat Dump Analyzer\n",
    "\n",
    "This notebook parses a Telegram chat history export (JSON) to find questions, requests for help, or specific keywords. \n",
    "It works entirely within Google Colab and does not send data to external servers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Setup & Imports\n",
    "!pip install --quiet pandas ipywidgets\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from google.colab import files, sheets\n",
    "from IPython.display import display, clear_output\n",
    "import ipywidgets as widgets\n",
    "\n",
    "print(\"Libraries installed and imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Configuration\n",
    "# Define keywords to search for in messages\n",
    "KEYWORDS = [\n",
    "    \"–ø–æ–¥—Å–∫–∞–∂–∏—Ç–µ\", \"–≤–æ–ø—Ä–æ—Å\", \"#–≤–æ–ø—Ä–æ—Å\", \"–ø–æ–º–æ—â—å\", \"–ø–æ–º–æ–≥–∏—Ç–µ\", \n",
    "    \"question\", \"help\", \"how to\", \"error\"\n",
    "]\n",
    "\n",
    "print(f\"Current keywords: {KEYWORDS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Upload File\n",
    "print(\"üì§ Please upload your Telegram JSON dump (result.json).\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "if uploaded:\n",
    "    input_file = list(uploaded.keys())[0]\n",
    "    print(f\"‚úÖ File loaded: {input_file}\")\n",
    "else:\n",
    "    print(\"‚ùå No file uploaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Parsing Logic\n",
    "def message_contains_keywords(text: str, keywords: list) -> bool:\n",
    "    \"\"\"Checks if message text contains any of the keywords.\"\"\"\n",
    "    text_lower = text.lower()\n",
    "    return any(keyword.lower() in text_lower for keyword in keywords)\n",
    "\n",
    "def extract_questions(input_file: str):\n",
    "    try:\n",
    "        with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    messages = data.get(\"messages\", data)\n",
    "    rows = []\n",
    "\n",
    "    for msg in messages:\n",
    "        if isinstance(msg, dict):\n",
    "            text = msg.get(\"text\", \"\")\n",
    "            # Handle Telegram's nested text entities\n",
    "            if isinstance(text, list):\n",
    "                text = \"\".join([t if isinstance(t, str) else t.get(\"text\", \"\") for t in text])\n",
    "\n",
    "            if isinstance(text, str) and message_contains_keywords(text, KEYWORDS):\n",
    "                name = msg.get(\"from\", \"‚Äî\")\n",
    "                username = msg.get(\"from_id\", \"‚Äî\")\n",
    "                date = msg.get(\"date\", \"‚Äî\")\n",
    "\n",
    "                rows.append({\n",
    "                    \"Date\": date,\n",
    "                    \"User\": name,\n",
    "                    \"ID\": username,\n",
    "                    \"Message\": text.strip()\n",
    "                })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    if not df.empty:\n",
    "        try:\n",
    "            df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "        except Exception:\n",
    "            pass\n",
    "    return df\n",
    "\n",
    "if 'input_file' in locals():\n",
    "    df = extract_questions(input_file)\n",
    "    print(f\"üîç Found {len(df)} messages matching keywords.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Please upload a file first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Interactive Dashboard\n",
    "if 'df' in locals() and not df.empty:\n",
    "    name_filter = widgets.Text(description='User:')\n",
    "    tag_filter = widgets.Text(description='ID:')\n",
    "    msg_filter = widgets.Text(description='Message:')\n",
    "    \n",
    "    def filter_table(change=None):\n",
    "        filtered = df[\n",
    "            df[\"User\"].str.contains(name_filter.value, case=False, na=False) &\n",
    "            df[\"ID\"].astype(str).str.contains(tag_filter.value, case=False, na=False) &\n",
    "            df[\"Message\"].str.contains(msg_filter.value, case=False, na=False)\n",
    "        ]\n",
    "        clear_output(wait=True)\n",
    "        display(ui, filtered)\n",
    "\n",
    "    ui = widgets.VBox([name_filter, tag_filter, msg_filter])\n",
    "    out = widgets.interactive_output(filter_table, {\n",
    "        'change': widgets.fixed(None)\n",
    "    })\n",
    "\n",
    "    display(ui, df)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No data to display.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Export to Google Sheets (Interactive)\n",
    "if 'df' in locals() and not df.empty:\n",
    "    sheet = sheets.InteractiveSheet(df=df)\n",
    "    print(\"Data loaded into Interactive Sheet below:\")\n",
    "    display(sheet)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
